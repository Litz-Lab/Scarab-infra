{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive quick start guide for the scarab stats library\n",
    "This jupyter notebook shows how to use the scarab stats library to obtain and graph statistics from scarab runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required data\n",
    "To use this library, you need to have run an experiment using a json experiment file (found in the dcworkloads repository). You will need a path to the experiment file used, the path to the files generated by the simulations (likely allbench_home/simpoint_flow/simulations), and the path to the traces used (likely /soe/hlitz/lab/traces on bohr3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading an experiment\n",
    "To load an experiment from a json file, you need to import the stats library and create a stat agregator object to load the data. Then use its `load_experiment_json` method to load the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scarab_stats import stat_aggregator\n",
    "\n",
    "# Create a stat aggregator object\n",
    "aggregator = stat_aggregator()\n",
    "\n",
    "# Paths to required data to load an experiment\n",
    "TRACE_PATH = \"/soe/hlitz/lab/traces/\"\n",
    "EXPERIMENT_PATH = \"/path/to/docker_home/exp.json\"\n",
    "SIMULATION_PATH = \"/path/to/docker_home/simpoint_flow/simulations/\"\n",
    "\n",
    "# Load the experiment file at EXPERIMENT_PATH using the simulations created at SIMULATION_PATH by running scarab,\n",
    "# using the traces located at TRACE_PATH\n",
    "# experiment = aggregator.load_experiment_json(EXPERIMENT_PATH, SIMULATION_PATH, TRACE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can load an experiment from a CSV file directly. CSV representations can be saved using experiment.to_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for experiment to be saved to\n",
    "SAVED_PATH = \"saved_experiment.csv\"\n",
    "\n",
    "# Save loaded experiment\n",
    "experiment.to_csv(SAVED_PATH)\n",
    "\n",
    "# Load experiment from saved CSV\n",
    "experiment = aggregator.load_experiment_csv(SAVED_PATH)\n",
    "\n",
    "# Or equivalently:\n",
    "# from scarab_stats import Experiment\n",
    "# experiment = Experiment(SAVED_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing data\n",
    "First you may want to check what different statistics, configurations, or workloads are available for graphing. The stats library provides the following funcitons to do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the experiments stored in the experiment file (usually just one)\n",
    "print(\"Experiments:\", \", \".join(experiment.get_experiments()))\n",
    "\n",
    "# Get the different configurations stored in the experiment file\n",
    "print(\"Configurations:\", \", \".join(experiment.get_configurations()))\n",
    "\n",
    "# Get the workloads that were ran\n",
    "print(\"Workloads:\", \", \".join(experiment.get_workloads()))\n",
    "\n",
    "# Get first 15 statistics stored in the file\n",
    "print(\"Statistics:\", \", \".join(experiment.get_stats()[:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now use the experiment to create graphs to visualize the data. There are several graphing functions to plot statistics aggregated at different levels, and to plot stats by their relative proportions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This code cell creates a bare minimum graph to plot \n",
    "\n",
    "# Reload the stat library if it is modified\n",
    "from importlib import reload\n",
    "import scarab_stats\n",
    "reload(scarab_stats)\n",
    "from scarab_stats import stat_aggregator\n",
    "\n",
    "# Create a stat aggregator object\n",
    "aggregator = stat_aggregator()\n",
    "\n",
    "# Path for experiment to be saved to\n",
    "SAVED_PATH = \"saved_experiment.csv\"\n",
    "\n",
    "# Save loaded experiment\n",
    "experiment.to_csv(SAVED_PATH)\n",
    "\n",
    "# Load experiment from saved CSV\n",
    "experiment = aggregator.load_experiment_csv(SAVED_PATH)\n",
    "\n",
    "# Get the name of the experiment as a string, and select workloads and config(s) to plot\n",
    "experiment_name = experiment.get_experiments()[0]\n",
    "workloads_to_plot = [\"clang\", \"gcc\", \"mongodb\", \"mysql\", \"postgres\", \"verilator\", \"xgboost\"]\n",
    "configs_to_plot = [\"baseline\", \"perfect_fdip_lookahead_10000\", \"perfect_fdip_lookahead_50000\", \"perfect_fdip_lookahead_100000\"]\n",
    "\n",
    "# A statistic where you want to plot raw numbers\n",
    "stat_to_plot = ['Periodic IPC']\n",
    "\n",
    "# Call the plot function\n",
    "aggregator.plot_workloads(experiment, stat_to_plot, workloads_to_plot, configs_to_plot, y_label=\"IPC\", x_label=\"Workloads\", average=True)\n",
    "\n",
    "# A statistic where you want to plot speedups\n",
    "stat_to_plot = ['Periodic IPC']\n",
    "\n",
    "# Call the plot function for speedups\n",
    "aggregator.plot_workloads_speedup(experiment, stat_to_plot, workloads_to_plot, configs_to_plot, y_label=\"IPC Speedup (%)\", x_label=\"Workloads\", speedup_baseline=\"bp1\", average=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This creates the same graph as above, but with custom colors\n",
    "\n",
    "# Create a custom list of colors to use\n",
    "colors = [(1,0,0), (0,1,0), (0,0,1), (1,1,0)]\n",
    "\n",
    "# Call the plot function\n",
    "aggregator.plot_workloads(experiment, stat_to_plot, workloads_to_plot, configs_to_plot, y_label=\"IPC\", x_label=\"Benchmarks\", average=True, colors=colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This code cell plots the relative proportions for MAP_STAGE_RECEIVED_OPS_[0-8]_count\n",
    "\n",
    "# Reload the stat library if it is modified\n",
    "from importlib import reload\n",
    "import scarab_stats\n",
    "reload(scarab_stats)\n",
    "from scarab_stats import stat_aggregator\n",
    "\n",
    "# Create a stat aggregator object\n",
    "aggregator = stat_aggregator()\n",
    "\n",
    "# Path for experiment to be saved to\n",
    "SAVED_PATH = \"saved_experiment.csv\"\n",
    "\n",
    "# Save loaded experiment\n",
    "experiment.to_csv(SAVED_PATH)\n",
    "\n",
    "# Load experiment from saved CSV\n",
    "experiment = aggregator.load_experiment_csv(SAVED_PATH)\n",
    "\n",
    "# Get the name of the experiment as a string, and select workloads and config(s) to plot\n",
    "experiment_name = experiment.get_experiments()[0]\n",
    "workloads_to_plot = [\"clang\", \"gcc\", \"mongodb\", \"mysql\", \"postgres\", \"verilator\", \"xgboost\"]\n",
    "configs_to_plot = [\"baseline\", \"perfect_fdip_lookahead_10000\", \"perfect_fdip_lookahead_50000\", \"perfect_fdip_lookahead_100000\"]\n",
    "\n",
    "# Get desired statistics\n",
    "stats_to_plot = [f\"MAP_STAGE_RECEIVED_OPS_{x}_count\" for x in range(0,9)]\n",
    "print(\"Plotting:\", stats_to_plot)\n",
    "\n",
    "# Print error if not in experiment\n",
    "for stat in stats_to_plot:\n",
    "    if not stat in experiment.get_stats():\n",
    "        print(f\"ERROR: Stat not in experiment: {stat}\")\n",
    "    \n",
    "# Get the experiment's name as a string, along with all available workloads and configs to plot\n",
    "experiment_name = experiment.get_experiments()[0]\n",
    "workloads_to_plot = experiment.get_workloads()\n",
    "configs_to_plot = experiment.get_configurations()\n",
    "\n",
    "# Plot the stats from workloads/configs/experiment in a bar graph, as their proportion of sum of all stats_to_plot\n",
    "# (like a pie chart, but in bar graph form)\n",
    "aggregator.plot_stacked(experiment, stats_to_plot, workloads_to_plot, configs_to_plot, y_label=\"MAP_STAGE_RECEIVED_OPS count\")\n",
    "aggregator.plot_stacked_fraction(experiment, stats_to_plot, workloads_to_plot, configs_to_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derived stats\n",
    "You can create your own stats using parenthesis, addition, subtraction, multiplication, and division of columns and scalars. To use variables, you can use a format string to inject the values of variables as scalars. Equations are written with similar format to the following: `new_stat_name = stat_name_1 + stat_name_2` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This code cell creates a derived stat that is the sum of all the stats plotted in the previous plot\n",
    "\n",
    "# Create equation that sums all of the stats\n",
    "equation = f\"MAP_STAGE_REVIEVED_OPS_ALL_COUNT = {' + '.join(stats_to_plot)}\"\n",
    "print(\"Equation:\", equation)\n",
    "\n",
    "# Print if it exists\n",
    "stat_exists = \"MAP_STAGE_REVIEVED_OPS_ALL_COUNT\" in experiment.get_stats()\n",
    "print(f\"Stat does {'' if stat_exists else 'not '}exist\")\n",
    "\n",
    "# Add stat as new entry\n",
    "experiment.derive_stat(equation)\n",
    "\n",
    "# Print if it exists now\n",
    "stat_exists = \"MAP_STAGE_REVIEVED_OPS_ALL_COUNT\" in experiment.get_stats()\n",
    "print(f\"Stat does {'' if stat_exists else 'not '}exist\")\n",
    "\n",
    "# Plot previous stats and new derived stats. To plot only derived stat, remove stats_to_plot\n",
    "new_stats_to_plot = stats_to_plot + [\"MAP_STAGE_REVIEVED_OPS_ALL_COUNT\"]\n",
    "aggregator.plot_workloads(experiment, new_stats_to_plot, workloads_to_plot, configs_to_plot, label_method=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
