# How to use
To use the python scarab stats api, you first need to run an experiment file on scarab.
You will need the path to the experiment json file, the path to the simulations, and the path to the traces used
The trace path is usually /soe/hlitz/lab/traces on NFS

The stats api is best used in a jupyter notebook. Any notebook that can be ran on the same machine as the simulations works.
I use vscode with the jupyter extention and the Remote - SSH extention to get a notebook running on bohr3

## Quickstart
NOTE: Please set 'slurm' optional parameter to true when using 'load_experiment_json' to load stats generated by the slurm runner.

### Using the quick start guide with jupyter notebooks
Prerequisites:
1) Install the jupyter notebook server with `pip3 install notebook` OR use the provided conda environment
2) Have serve_jupyter.sh in the directory you want to create the server
3) Have scarab_stats_quick_start.ipynb in the directory you want to create the server
4) Have scarab_stats.py in the directory you want to plot the figures
**You need the quick start guide and serve_jupyter.sh in the same directory**

Using conda:
Please run `conda env create --file quickstart_env.yaml` on the machine running the jupyter notebook server using the provided quickstart_env.yaml file. This will provide you with all the notebooks pip library required for running the server. If you have already created the statslib conda environment, run `conda activate statslib`.

Running the guide:
Run `pip3 install notebook` if notebook is not installed. If your distribution is adopting PEP 668 (Making Python base environments as "externally managed"), use venv. Then you can run ./serve_jupyter.sh on bohr3 to start the server. It will take around 4 seconds to get a port, start the server, and generate the kill script.

To use it, you will need to create a SSH tunnel between bohr and your machine to forward the http traffic to your local machine. Commands to create and destroy the tunnel are automatically generated by the script and printed to stdout for the user to copy and paste into their terminal.
**This is not required if using vscode's Remote - SSH extension**. It will automatically create and close ssh tunnels to forward the traffic. The above **is** required if you use ssh in your terminal to access bohr.

Closing the guide:
If you created a SSH tunnel on your machine, you should close it. Use `ps -a -o pid,cmd | grep ssh` to find the process ID on your machine of the command you used to create the tunnel: `ssh -NfL localhost:PORT:localhost:PORT USERNAME@bohr3.soe.ucsc.edu`. Then use `kill PID` on the process id.

Then on bohr, run the stop_jupyter.sh script generated when the server was started.

Files generated:
The script will create two new files in the local directory to facilitate the conenction. The first is the kill script to kill the child notebook process (./stop_jupyter.sh), and the other is the log for the jupyter server (jupyter_log.txt). This log is useful for debugging, and is required for the script to grab the session token for the server.

### Using the library
To use it, first import the library using
`import scarab_stats`

Then create a `stat_aggregator` to load an experiment from the stat files produces by scarab
`aggregator = scarab_stats.stat_aggregator()`

And finally load your experiment using the `load_experiment_json` function. It requires a path to the experiment file, a path to the simulations directory, and a parth to the traces dierectory
Ex (using stats from run.sh):
`experiment = aggregator.load_experiment_json("allbench_home/exp2.json", "allbench_home/simpoint_flow/simulations", "/soe/hlitz/lab/traces/")`

Ex (using stats from run_slurm.py):
`experiment = aggregator.load_experiment_json("allbench_home/exp2.json", "allbench_home/simpoint_flow/simulations", "/soe/hlitz/lab/traces/", slurm=True)`

Then you can use any of the `stat_aggregator` class's plotting functions, or retreive data directly from the experiment

## Documentation
### stat_aggregator
#### load_experiment_csv
Arguments: (path: str)

Loads an experiment from a csv file. Equivalent to `Experiment(path)`

- path: Path to the csv file of the experiment

#### load_experiment_json
Arguments: (experiment_file: str, simulations_path: str, simpoints_path: str, slurm: bool = False)

This function returns an experiment object loaded from the path provided. 

- experiment_file: the json file used to run the experiment containing all the data about it
- simulations_path: the path to the simulations directory created by scarab
- simpoints_path: the path to the traces that contain information about all the simpoints (/soe/hlitz/lab/traces/)
- slurm: uses the slurm runner filepath structure to load stat files when true. Uses old infrastructure format (simulations_path/simpointflow/simulations/..) when false

#### plot_workloads 
Arguments: (experiment: Experiment, stats: List[str], workloads: List[str], 
            configs: List[str], speedup_baseline: str = None, title: str = "Default Title", x_label: str = "", 
            y_label: str = "", logscale: bool = False, bar_width:float = 0.35, 
            bar_spacing:float = 0.05, workload_spacing:float = 0.3, average: bool = False, colors = None, plot_name = None)

Generates a plot of all requested statistics aggregating stats across all simpoints for each workload. Can plot multiple workloads at once

- Experiment: The experiment object to be used
- experiment_name: The string name of the experiment, from the json file
- stats: A list of the names of all the desired stats to be plotted
- workloads: A list of the names of all workloads from the experiment to be plotted
- configs: A list of all the configs from the experiment to be plotted (minus the baseline, if desired)
- THE FOLLOWING ARE OPTIONAL
- speedup_baseline: If calculating speedups over a baseline config is desired put the name of the baseline config here
- title: The title of the plot
- x_label: The label of the x axis of the plot
- y_label: The label of the y axis of the plot. Default is Count or Speedup depending on if baseline provided
- logscale: Set y axis to logorithmic scaling
- bar_width: The width of bars for statistics
- bar_spacing: The size of the space between stat bars
- workload_spacing: The additional spacing added to differentiate stats of different workloads
- average: Add an extra group of the averages of all the stats
- colors: A list of colors for each different stat. Chosen dynamically if not set
- plot_name: The name of the file to save the plot in. By default it will show the graph without saving

#### plot_simpoints
Arguments: (experiment: Experiment, stats: List[str], workload: str, 
            configs: List[str], simpoints: List[str] = None, speedup_baseline: str = None, 
            title: str = "Default Title", x_label: str = "", y_label: str = "", 
            logscale: bool = False, bar_width:float = 0.35, bar_spacing:float = 0.05, workload_spacing:float = 0.3, 
            average: bool = False, colors = None, plot_name = None):

Generates a plot of all requested statistics, does NOT aggregate stats across each workload. Can plot multiple workloads and configs at once

- Experiment: The experiment object to be used
- experiment_name: The string name of the experiment, from the json file
- stats: A list of the names of all the desired stats to be plotted
- workload: The name of the workload from the experiment to be plotted
- configs: A list of all the configs from the experiment to be plotted (minus the baseline, if desired)
- THE FOLLOWING ARE OPTIONAL
- simpoints: Select specific simpoints to plot, and ignore rest. Default option plots all
- speedup_baseline: If calculating speedups over a baseline config is desired put the name of the baseline config here
- title: The title of the plot
- x_label: The label of the x axis of the plot
- y_label: The label of the y axis of the plot. Default is Count or Speedup depending on if baseline provided
- logscale: Set y axis to logorithmic scaling
- bar_width: The width of bars for statistics
- bar_spacing: The size of the space between stat bars
- workload_spacing: The additional spacing added to differentiate stats of different workloads
- average: Add an extra group of the averages of all the stats
- colors: A list of colors for each different stat. Chosen dynamically if not set
- plot_name: The name of the file to save the plot in. By default it will show the graph without saving

#### plot_configs
Arguments: (experiment: Experiment, stats: List[str], workloads: List[str], 
            configs: List[str], speedup_baseline: str = None, 
            title: str = "Default Title", x_label: str = "", y_label: str = "", 
            logscale: bool = False, bar_width:float = 0.35, bar_spacing:float = 0.05, workload_spacing:float = 0.3, 
            average: bool = False, colors = None, plot_name = None)

Generates a plot of all requested configs aggregating across workloads (with even weighting). Can plot multiple configs at once

- Experiment: The experiment object to be used
- experiment_name: The string name of the experiment, from the json file
- stats: A list of the names of all the desired stats to be plotted
- workloads: A list of the names of all workloads from the experiment to be plotted
- configs: A list of all the configs from the experiment to be plotted (minus the baseline, if desired)
- THE FOLLOWING ARE OPTIONAL
- speedup_baseline: If calculating speedups over a baseline config is desired put the name of the baseline config here
- title: The title of the plot
- x_label: The label of the x axis of the plot
- y_label: The label of the y axis of the plot. Default is Count or Speedup depending on if baseline provided
- logscale: Set y axis to logorithmic scaling
- bar_width: The width of bars for statistics
- bar_spacing: The size of the space between stat bars
- workload_spacing: The additional spacing added to differentiate stats of different workloads
- average: Add an extra group of the averages of all the stats
- colors: A list of colors for each different stat. Chosen dynamically if not set
- plot_name: The name of the file to save the plot in. By default it will show the graph without saving

#### plot_stacked
Arguments: (experiment: Experiment, stats: List[str], workloads: List[str], 
            configs: List[str], title: str = "Default Title", 
            bar_width:float = 0.35, bar_spacing:float = 0.05, workload_spacing:float = 0.3, colors = None, plot_name = None)

Generates a plot where the requested statistics are stacked into one bar to see the ratios between them. An example would be plotting 'BTB_OFF_PATH_MISS_count' and 'BTB_OFF_PATH_HIT_count' to show the ratio of hits and misses of the BTB when off path. Can only do one set of stats per graph right now, but can plot across multiple workloads and configs.

- Experiment: The experiment object to be used
- experiment_name: The string name of the experiment, from the json file
- stats: A list of the names of all the desired stats to be plotted
- workloads: A list of the names of all workloads from the experiment to be plotted
- configs: A list of all the configs from the experiment to be plotted (minus the baseline, if desired)
- THE FOLLOWING ARE OPTIONAL
- title: The title of the plot
- bar_width: The width of bars for statistics
- bar_spacing: The size of the space between stat bars
- workload_spacing: The additional spacing added to differentiate stats of different workloads
- colors: A list of colors for each different stat. Chosen dynamically if not set
- plot_name: The name of the file to save the plot in. By default it will show the graph without saving

#### plot_speedups
Arguments:(experiment: Experiment, experiment_baseline: Experiment, speedup_metric: str, 
            title: str = None, x_label: str = "", y_label: str = "", 
            baseline_conf = None, bar_width:float = 0.35, 
            bar_spacing:float = 0.05, workload_spacing:float = 0.3, 
            colors = None, plot_name = None, relative_lbls = False)

Plots speedup of each workload (aggregating all simpoints) for every config, of experiment/experiment_baseline. All configs must be present in BOTH experiment files. You can specify a baseline config to use for calculating speedups of speedups, which can be thought of as calculating exeriment(all_confs/baseline_conf)/exeriment_baseline(all_confs/baseline_conf).

- experiment: Experiment containing stats from improved code, the experiment runs you want to find the speedup of
- experiment_baseline: Experiment containing the baseline to compare `experiment` to. Contains stats from the old/unimproved code
- speedup_metric: What stat should be used for evaluating the speedup of each workload. Must be present in both experiments
- THE FOLLOWING ARE OPTIONAL
- title: The title to be displayed at the top of the graph. The default option states what experiments are being used to calculate the speedups
- x_label: The label to be put on the x axis of the graph
- y_label: The label to be put on the y axis of the graph. The default states the stat used for calculating speedup
- baseline_conf: Use this option to specify a baseline config, ignored if not set
- bar_width: The width of bars for statistics
- bar_spacing: The size of the space between stat bars
- workload_spacing: The additional spacing added to differentiate stats of different workloads
- colors: A list of colors for each different stat. Chosen dynamically if not set
- plot_name: The name of the file to save the plot in. By default it will show the graph without saving
- relative_lbls: If true, speedups are represented as "+20.0%" or "-5.0%". If false, the same speedups would be labeled as "1.2" and "0.95" respectively. **Default True**

#### diff_stats_all
Arguments: (experiment_baseline: Experiment, experiment_new: Experiment, 
            diff_thresh: float = 50, must_contain: str = None)

**NOTE:** Partially implemented due to diff_stats being more useful. Creates a lot of data that is difficult to manage. Two csvs (dev_dbg.csv and avg_dbg.csv) are created containing the standard deviation and average data (respectively) for analysis if needed

Determines which stats are 'differing' and calculates their averages and standard deiations. Does not aggregate simpoints, and cannot do recursive diffs (for these features see `diff_stats`)

- experiment_baseline: Experiment containing the baseline to compare `experiment` to. Contains stats from the old/unimproved code
- experiment_new: Experiment containing stats from improved code, the experiment runs you want to find the speedup of
- diff_thresh: The threshold difference from the baseline required to consider a stat as differing
- must_contain: A string that must be found in stat names to select them for diff checking. **Ignored if None (default)**. This is useful because there are different types of stats. count or count_total stats differ by wildly varying amounts, so it is useful to only select the pct stats and check use a diff_thresh of 5 to get stats with a 5% difference.

#### diff_stats 
Arguments: (experiment_baseline: Experiment, experiment_new: Experiment, 
            workload: str, config: str, diff_thresh: float = 0.05, 
            must_contain: str = None, baseline_config: str = None,
            diff_type: str = "differential")

Calculates the differing stats between two experiments. Can take a difference of a differece if a baseline config is provided. Multiple diff types are allowed

Arguments:
- experiment_baseline: Old, unimproved experiment runs
- experiment_new: New experiment which need improvement measured
- workload: The workload to measure improvements on
- config: The configuration to measure improvements on
- diff_thresh: The threshold at which something is considered different
- must_contain: Stats not containing this substring are ignored. **All stats are considered if must_contain is None (default)**
- baseline_config: For multi-level diffs, use this to choose a config as a baseline. **Ignored if None (default)**. If set, the diff is as follows experiment_new(config/baseline_config)/experiment_baseline(config/baseline_config)
- diff_type: The type of diff to be used. **Default is "differential"**. Two types of diff are implemented, "difference" and "differential". "difference" is implemented using subtraction so the magnitude of stat differences ranges wildly, and it can be hard to tell which experiment performed better based on the sign when using a basline_config. "differential" is implemented using divison and inherently 'normalizes' the data, so all differences are decimal ratios. When the baseline stat is higher than the new stat, the stat will be represented as the negative of its reciprocal (-1/x if x<1 and x != 0 else x for x in stats). This meand if the *baseline* stat is 4 greater, then diff_stats will print it as a difference of -4 instead of 0.25. 

### Experiment
The experiment class is used to store all the data about an experiment, containing all stats

#### Constructor
Arguments: (path: str)

Using Experiment(path) will automatically load an experiment from a saved csv file

- path: path of saved file

#### retrieve_stats
Arguments: (experiment: str, config: List[str], stats: List[str], workload: List[str], 
            aggregation_level:str = "Workload", simpoints: List[str] = None)

Gets statistics as a dictionary format is different depending on agregation level. Each one can be accessed using the following keys:
aggregation_level = "Workload": f"{config} {workload} {statistic}"
aggregation_level = "Simpoint": f"{config} {workload} {simpoint} {statistic}"
aggregation_level = "Config": f"{config} {statistic}"

- experiment: The name of the experiment you want data from
- config: A list of the configurations you want data from
- workload: A list of workloads you want data from
- THE FOLLOWING ARE NOT REQUIRED
- aggregation_level: The level that stats should be agregated to. "Workload" "Simpoint" or "Config"
- simpoints: For aggregation level "Simpoint", optionally provide which simpoints you want data from. Default is all

#### derive_stat
Arguments: (equation:str, overwrite:bool=True, agg_first:bool=True)

Creates a new stat column using the given equation. Format should be similar to `new_stat_name = stat_name + stat_name_2 * 42`. Format strings can be used to insert variables

- equation: The equation to be used to derive a new statistic. + - * / all work, with column names or number literals.
- overwrite: If set to false, will error if user attempts to overwrite the value of an existing stat. When enabled (default), it will replace the value of the stat if it exists. Cannot be used on stats collected directly from scarab.
- agg_first: If set to false, do not carry out simpoint weighting during stat creation. When set to true (default), it will aggregate/weight simpoints during the data retrival step while deriving your stat.

#### to_csv
Arguments: (path: str)

Saves experiment as csv file

- path: The path for the csv file to be generated

#### get_experiments
Arguments: None

Returns a list of all the names of all the experiments contained in the experiment object
**ORDERING IS NON-DETERMINISTIC**. If you rely on the order of get_experiments for retreiving your data the experimentes selected may be different run-to-run.

#### get_configurations
Arguments: None

Returns a list of all the names of all the configurations contained in the experiment object
**ORDERING IS NON-DETERMINISTIC**. If you rely on the order of get_configurations for retreiving your data the configurations selected may be different run-to-run.

#### get_workloads
Arguments: None

Returns a list of all the names of all the workloads contained in the experiment object
**ORDERING IS NON-DETERMINISTIC**. If you rely on the order of get_workloads for retreiving your data the workloads selected may be different run-to-run.

#### get_stats
Arguments: None

Returns a list of all the names of all the stats contained in the experiment object
**ORDERING IS NON-DETERMINISTIC**. If you rely on the order of get_stats for retreiving your data the stats selected may be different run-to-run.